{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72ceadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, VerificationMode\n",
    "from transformers import AutoTokenizer\n",
    "import polars as pl\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5b6d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALECT_PREFIXES = [\n",
    "    \"terjemah ke johor:\",\n",
    "    \"terjemah ke kelantan:\",\n",
    "    \"terjemah ke sabah:\",\n",
    "    \"terjemah ke sarawak:\",\n",
    "    \"terjemah ke kedah:\",\n",
    "    \"terjemah ke pahang:\",\n",
    "    \"terjemah ke perak:\",\n",
    "    \"terjemah ke terengganu:\",\n",
    "    \"terjemah ke melaka:\",\n",
    "    \"terjemah ke negeri sembilan:\",\n",
    "    \"terjemah ke pasar Melayu:\",\n",
    "]\n",
    "\n",
    "STANDARD_PREFIXES = [\n",
    "    \"terjemah ke Melayu:\",\n",
    "    \"terjemah ke Inggeris:\",\n",
    "    # \"terjemah ke Mandarin:\",\n",
    "    # \"terjemah ke Tamil:\",\n",
    "    \"terjemah ke Manglish:\",\n",
    "    # \"terjemah ke Cantonese:\",\n",
    "]\n",
    "\n",
    "ALLOWED_PREFIXES = DIALECT_PREFIXES + STANDARD_PREFIXES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d6514",
   "metadata": {},
   "source": [
    "# Preclean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3f5418a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a single shard\n",
    "test_stage = \"stage2-part1\"\n",
    "test_shard_idx = 0\n",
    "test_num_shards = 2\n",
    "\n",
    "data_file = f\"{test_stage}/train-{str(test_shard_idx).rjust(5, '0')}-of-{str(test_num_shards).rjust(5, '0')}.parquet\"\n",
    "dataset = load_dataset(\n",
    "    \"mesolitica/Malaysian-Translation\",\n",
    "    data_files=data_file,\n",
    "    verification_mode=VerificationMode.NO_CHECKS\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74c4234e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preclean_data(data:pl.LazyFrame) -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    Preclean data by:\n",
    "    - Filtering by allowed prefixes\n",
    "    - Removing self-translation\n",
    "    - Removing empty source or target\n",
    "    - Removing too long source or target\n",
    "    - Removing too many non-alphanumeric characters,there is some code block data that is mostly not translated for the task\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter by allowed prefixes\n",
    "#     print(\"Original data:\")\n",
    "#     print(data.show())\n",
    "    \n",
    "    def _remove_non_alphanumeric(text:str) -> str:\n",
    "        return re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    \n",
    "    data_lf = (\n",
    "        data\n",
    "        .filter(pl.col(\"prefix\").str.to_lowercase().str.strip_chars().is_in([p.lower() for p in ALLOWED_PREFIXES])) # filter by allowed prefixes (lowercased)\n",
    "        .filter(pl.col(\"src\") != pl.col(\"tgt\")) #remove self-translation\n",
    "        .filter(pl.col(\"src\").str.len_chars() > 0,\n",
    "                pl.col(\"tgt\").str.len_chars() > 0) #remove empty source or target\n",
    "        .filter(pl.col(\"src\").str.len_chars() < 1000,\n",
    "                pl.col(\"tgt\").str.len_chars() < 1000) #remove too long source or target\n",
    "        .filter(pl.col(\"src\").map_elements(_remove_non_alphanumeric).str.len_chars() > 0,\n",
    "                pl.col(\"tgt\").map_elements(_remove_non_alphanumeric).str.len_chars() > 0) #remove too many non-alphanumeric characters\n",
    "    )\n",
    "    \n",
    "#     print(\"Filtered data:\")\n",
    "#     print(data_lf.show())\n",
    "    \n",
    "    return data_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cbdfb1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: 87101 examples\n",
      "Original data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>src</th><th>tgt</th><th>prefix</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Wah, ramai sungguh orang membe…</td><td>&quot;Pengkritik telah menuduh badan…</td><td>&quot;terjemah ke Melayu: &quot;</td></tr><tr><td>&quot;Wah, ramai sungguh orang membe…</td><td>&quot;Critics have accused the Malay…</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;Mengapa sesetengah pengkritik …</td><td>&quot;terjemah ke Melayu: &quot;</td></tr><tr><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;Why have some critics accused …</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;Pengkritik telah menuduh badan…</td><td>&quot;Wah, ramai sungguh orang membe…</td><td>&quot;terjemah ke johor: &quot;</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Filtered data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>src</th><th>tgt</th><th>prefix</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;Mengapa sesetengah pengkritik …</td><td>&quot;terjemah ke Melayu: &quot;</td></tr><tr><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;Why have some critics accused …</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;Mengapa sesetengah pengkritik …</td><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;terjemah ke johor: &quot;</td></tr><tr><td>&quot;Why have some critics accused …</td><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;terjemah ke johor: &quot;</td></tr><tr><td>&quot;Memang la kerajaan kita ni dah…</td><td>&quot;Sudah tentu, berikut ialah soa…</td><td>&quot;terjemah ke Melayu: &quot;</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Cleaned: 41350 examples\n",
      "Removed: 45751 examples (52.5%)\n"
     ]
    }
   ],
   "source": [
    "data_lf = pl.LazyFrame(list(dataset['train']))\n",
    "len_df = data_lf.select(pl.len()).collect()\n",
    "print(f\"Original: {len_df.item()} examples\")\n",
    "\n",
    "\n",
    "cleaned_lf = preclean_data(data_lf)\n",
    "cleaned_df = cleaned_lf.collect()\n",
    "\n",
    "print(f\"Cleaned: {len(cleaned_df)} examples\")\n",
    "print(f\"Removed: {len_df.item() - len(cleaned_df)} examples ({100*(len_df.item() - len(cleaned_df))/len_df.item():.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bed2641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_shard(stage, shard_idx, num_shards, output_dir):\n",
    "    \"\"\"Process a single shard, clean it, and save as parquet\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    data_file = f\"{stage}/train-{str(shard_idx).rjust(5, '0')}-of-{str(num_shards).rjust(5, '0')}.parquet\"\n",
    "    \n",
    "    # Load\n",
    "    dataset = load_dataset(\n",
    "        \"mesolitica/Malaysian-Translation\",\n",
    "        data_files=data_file,\n",
    "        verification_mode=VerificationMode.NO_CHECKS\n",
    "    )\n",
    "    \n",
    "    # Convert to Polars and clean\n",
    "    data_lf = pl.LazyFrame(list(dataset['train']))\n",
    "    cleaned_lf = preclean_data(data_lf)\n",
    "    cleaned_df = cleaned_lf.collect()\n",
    "    \n",
    "    # Save as parquet\n",
    "    output_file = output_path / f\"{stage.replace('/', '_')}_shard_{shard_idx:05d}.parquet\"\n",
    "    cleaned_df.write_parquet(str(output_file))\n",
    "    \n",
    "    return len(cleaned_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ac571bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed shard 0 of 2 for stage2-part1\n",
      "Processed 41350 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:11<00:00, 11.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed shard 1 of 2 for stage2-part1\n",
      "Processed 9750 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up output directory\n",
    "# Thinking of trying stage2-coding-blocks-dialects, but it's too much effort for now just to get the data from the comments\n",
    "STAGES_TO_PROCESS = {\n",
    "    \"stage2-part1\": 2, # Mostly Dialects \n",
    "}\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "output_dir = \"../data/processed/cleaned_shards/\"\n",
    "\n",
    "for stage, num_shards in tqdm(STAGES_TO_PROCESS.items()):\n",
    "    for shard_idx in range(num_shards):\n",
    "        count = process_shard(stage, shard_idx, num_shards, output_dir)\n",
    "        print(f\"Processed shard {shard_idx} of {num_shards} for {stage}\")\n",
    "        print(f\"Processed {count} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0c3b9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../data/processed/cleaned_shards/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02e83309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['stage2-part1_shard_00000.parquet', 'stage2-part1_shard_00001.parquet']\n"
     ]
    }
   ],
   "source": [
    "data_files = os.listdir(output_dir)\n",
    "print(data_files)\n",
    "\n",
    "lazyframes = [\n",
    "    pl.scan_parquet(f\"{output_dir}/{data_file}\")\n",
    "    for data_file in data_files\n",
    "]\n",
    "\n",
    "combined_lf = pl.concat(lazyframes, how=\"vertical_relaxed\", rechunk=True)\n",
    "\n",
    "combined_df = combined_lf.collect()\n",
    "combined_df.write_parquet(f\"{output_dir}/combined_shards_stage_2.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "90a67c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>src</th><th>tgt</th><th>prefix</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;Mengapa sesetengah pengkritik …</td><td>&quot;terjemah ke Melayu: &quot;</td></tr><tr><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;Why have some critics accused …</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;Mengapa sesetengah pengkritik …</td><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;terjemah ke johor: &quot;</td></tr><tr><td>&quot;Why have some critics accused …</td><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;terjemah ke johor: &quot;</td></tr><tr><td>&quot;Memang la kerajaan kita ni dah…</td><td>&quot;Sudah tentu, berikut ialah soa…</td><td>&quot;terjemah ke Melayu: &quot;</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stage2_train = pl.scan_parquet(f\"{output_dir}/combined_shards_stage_2.parquet\")\n",
    "stage2_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37814dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>prefix</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;terjemah ke Inggeris: &quot;</td><td>12910</td></tr><tr><td>&quot;terjemah ke Melayu: &quot;</td><td>12676</td></tr><tr><td>&quot;terjemah ke pasar Melayu: &quot;</td><td>3933</td></tr><tr><td>&quot;terjemah ke sarawak: &quot;</td><td>2425</td></tr><tr><td>&quot;terjemah ke kedah: &quot;</td><td>2263</td></tr><tr><td>&quot;terjemah ke pahang: &quot;</td><td>2209</td></tr><tr><td>&quot;terjemah ke terengganu: &quot;</td><td>2173</td></tr><tr><td>&quot;terjemah ke johor: &quot;</td><td>2165</td></tr><tr><td>&quot;terjemah ke kelantan: &quot;</td><td>2162</td></tr><tr><td>&quot;terjemah ke melaka: &quot;</td><td>2161</td></tr><tr><td>&quot;terjemah ke sabah: &quot;</td><td>2070</td></tr><tr><td>&quot;terjemah ke negeri sembilan: &quot;</td><td>2031</td></tr><tr><td>&quot;terjemah ke perak: &quot;</td><td>1917</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "    stage2_train\n",
    "    .unique(subset=[\"src\", \"tgt\", \"prefix\"])\n",
    "    .group_by(\n",
    "        \"prefix\",\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(\"prefix\").count().alias(\"count\")\n",
    "    )\n",
    "    .sort(\"count\", descending=True)\n",
    "    .show(100)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1c503b",
   "metadata": {},
   "source": [
    "# Grouping for train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e4dae8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>semantic_key</th><th>count</th><th>prefix</th><th>src</th><th>tgt</th></tr><tr><td>u64</td><td>u32</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>14022566730409109112</td><td>4</td><td>&quot;terjemah ke pasar Melayu: &quot;</td><td>&quot;Nama pengguna PostgreSQL tidak…</td><td>&quot;Weyh, username PostgreSQL tak …</td></tr><tr><td>14022566730409109112</td><td>4</td><td>&quot;terjemah ke pasar Melayu: &quot;</td><td>&quot;Nama pengguna PostgreSQL tidak…</td><td>&quot;Weyh, username PostgreSQL tak …</td></tr><tr><td>14022566730409109112</td><td>4</td><td>&quot;terjemah ke Melayu: &quot;</td><td>&quot;Weyh, username PostgreSQL tak …</td><td>&quot;Nama pengguna PostgreSQL tidak…</td></tr><tr><td>14022566730409109112</td><td>4</td><td>&quot;terjemah ke Inggeris: &quot;</td><td>&quot;Weyh, username PostgreSQL tak …</td><td>&quot;Nama pengguna PostgreSQL tidak…</td></tr><tr><td>12067363625207878782</td><td>4</td><td>&quot;terjemah ke pasar Melayu: &quot;</td><td>&quot;Adakah mungkin untuk mengatur …</td><td>&quot;Wei bro, boleh ke nak susun ba…</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stage2_train_lf = (\n",
    "    stage2_train.with_columns(\n",
    "        semantic_key=pl.struct([\"src\", \"tgt\"])\n",
    "        .map_elements(\n",
    "            lambda x: \"|||\".join(sorted([\n",
    "                x[\"src\"].lower(), \n",
    "                x[\"tgt\"].lower()\n",
    "            ])),\n",
    "            return_dtype=pl.Utf8\n",
    "        )\n",
    "        .hash()\n",
    "    )\n",
    "    .sort(\n",
    "        [\n",
    "            \"src\",\n",
    "            \"tgt\",\n",
    "        ]\n",
    "    )\n",
    "    .group_by(\"semantic_key\")\n",
    "    .agg(\n",
    "        pl.col(\"semantic_key\").count().alias(\"count\"),\n",
    "        pl.col(\"prefix\").alias(\"prefix\"),\n",
    "        pl.col(\"src\").alias(\"src\"),\n",
    "        pl.col(\"tgt\").alias(\"tgt\")\n",
    "    )\n",
    "    .explode([\"src\", \"tgt\", \"prefix\"])\n",
    "    .sort([\"count\", \"semantic_key\"], descending=True)\n",
    "    .show()\n",
    ")\n",
    "\n",
    "stage2_train_lf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "427f46b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<i>naive plan: (run <b>LazyFrame.explain(optimized=True)</b> to see the optimized plan)</i>\n",
       "    <p></p>\n",
       "    <div> WITH_COLUMNS:<p></p> [col(\"src\").as_struct([col(\"tgt\")]).python_udf().hash().alias(\"semantic_key\")] <p></p>  Parquet SCAN [../data/processed/cleaned_shards//combined_shards_stage_2.parquet]<p></p>  PROJECT */3 COLUMNS<p></p>  ESTIMATED ROWS: 51100</div>"
      ],
      "text/plain": [
       "<LazyFrame at 0x742ABAC167B0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stage2_train_lf = (\n",
    "    stage2_train.with_columns(\n",
    "        semantic_key=pl.struct([\"src\", \"tgt\"])\n",
    "        .map_elements(\n",
    "            lambda x: \"|||\".join(sorted([\n",
    "                x[\"src\"].strip().lower(), \n",
    "                x[\"tgt\"].strip().lower()\n",
    "            ])),\n",
    "            return_dtype=pl.Utf8\n",
    "        )\n",
    "        .hash()\n",
    "    )\n",
    ")\n",
    "\n",
    "stage2_train_lf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd035e23",
   "metadata": {},
   "source": [
    "## Check Stage 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0e2ce3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stage1_train = pl.scan_parquet(\"/home/alif/Codes/ml-eng-assessment/src/data/processed/cleaned_shards/combined_shards.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d4b58840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (15, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>prefix</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;terjemah ke Inggeris: &quot;</td><td>1002115</td></tr><tr><td>&quot;terjemah ke Tamil: &quot;</td><td>614556</td></tr><tr><td>&quot;terjemah ke Melayu: &quot;</td><td>526216</td></tr><tr><td>&quot;terjemah ke Mandarin: &quot;</td><td>501595</td></tr><tr><td>&quot;terjemah ke Cantonese: &quot;</td><td>16920</td></tr><tr><td>&quot;terjemah ke kedah: &quot;</td><td>3703</td></tr><tr><td>&quot;terjemah ke sarawak: &quot;</td><td>3539</td></tr><tr><td>&quot;terjemah ke terengganu: &quot;</td><td>3349</td></tr><tr><td>&quot;terjemah ke melaka: &quot;</td><td>3342</td></tr><tr><td>&quot;terjemah ke johor: &quot;</td><td>3309</td></tr><tr><td>&quot;terjemah ke pahang: &quot;</td><td>3247</td></tr><tr><td>&quot;terjemah ke sabah: &quot;</td><td>3230</td></tr><tr><td>&quot;terjemah ke negeri sembilan: &quot;</td><td>3130</td></tr><tr><td>&quot;terjemah ke kelantan: &quot;</td><td>3104</td></tr><tr><td>&quot;terjemah ke perak: &quot;</td><td>3026</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>semantic_key</th><th>count</th></tr><tr><td>u64</td><td>u32</td></tr></thead><tbody><tr><td>8285688865311977291</td><td>4432</td></tr><tr><td>8802236912260417209</td><td>2098</td></tr><tr><td>3108883538717360724</td><td>794</td></tr><tr><td>15128987433392456156</td><td>758</td></tr><tr><td>16613926417508413196</td><td>610</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "    stage1_train\n",
    "    .unique(subset=[\"src\", \"tgt\", \"prefix\"])\n",
    "    .group_by(\n",
    "        \"prefix\",\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(\"prefix\").count().alias(\"count\")\n",
    "    )\n",
    "    .sort(\"count\", descending=True)\n",
    "    .show(20)\n",
    ")\n",
    "\n",
    "(\n",
    "    stage1_train.with_columns(\n",
    "        semantic_key=pl.struct([\"src\", \"tgt\"])\n",
    "        .map_elements(\n",
    "            lambda x: \"|||\".join(sorted([\n",
    "                x[\"src\"].strip().lower(), \n",
    "                x[\"tgt\"].strip().lower()\n",
    "            ])),\n",
    "            return_dtype=pl.Utf8\n",
    "        )\n",
    "        .hash()\n",
    "    )\n",
    "    .sort(\n",
    "        [\n",
    "            \"src\",\n",
    "            \"tgt\",\n",
    "            \"prefix\"\n",
    "        ]\n",
    "    )\n",
    "    .group_by(\"semantic_key\")\n",
    "    .agg(\n",
    "        pl.col(\"semantic_key\").count().alias(\"count\")\n",
    "    )\n",
    "    .sort(\"count\", descending=True)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3d9660e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive plan: (run LazyFrame.explain(optimized=True) to see the optimized plan)\n",
      "\n",
      "FILTER col(\"prefix\").str.to_lowercase().str.strip_chars([null]).is_in([[\"terjemah ke johor:\", \"terjemah ke kelantan:\", … \"terjemah ke manglish:\"]])\n",
      "FROM\n",
      "   WITH_COLUMNS:\n",
      "   [col(\"src\").as_struct([col(\"tgt\")]).python_udf().hash().alias(\"semantic_key\")] \n",
      "    Parquet SCAN [/home/alif/Codes/ml-eng-assessment/src/data/processed/cleaned_shards/combined_shards.parquet]\n",
      "    PROJECT */3 COLUMNS\n",
      "    ESTIMATED ROWS: 3324040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>src</th><th>tgt</th><th>prefix</th><th>semantic_key</th></tr><tr><td>str</td><td>str</td><td>str</td><td>u64</td></tr></thead><tbody><tr><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;Mengapa sesetengah pengkritik …</td><td>&quot;terjemah ke Melayu: &quot;</td><td>6827693803332865790</td></tr><tr><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;Why have some critics accused …</td><td>&quot;terjemah ke Inggeris: &quot;</td><td>13281119773419373378</td></tr><tr><td>&quot;Mengapa sesetengah pengkritik …</td><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;terjemah ke johor: &quot;</td><td>6827693803332865790</td></tr><tr><td>&quot;Why have some critics accused …</td><td>&quot;Apasal la setengah orang ni su…</td><td>&quot;terjemah ke johor: &quot;</td><td>13281119773419373378</td></tr><tr><td>&quot;Memang la kerajaan kita ni dah…</td><td>&quot;Sudah tentu, berikut ialah soa…</td><td>&quot;terjemah ke Melayu: &quot;</td><td>7491223322354480547</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (12, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>prefix</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;terjemah ke Inggeris: &quot;</td><td>1002115</td></tr><tr><td>&quot;terjemah ke Melayu: &quot;</td><td>526216</td></tr><tr><td>&quot;terjemah ke kedah: &quot;</td><td>3703</td></tr><tr><td>&quot;terjemah ke sarawak: &quot;</td><td>3539</td></tr><tr><td>&quot;terjemah ke terengganu: &quot;</td><td>3349</td></tr><tr><td>&quot;terjemah ke melaka: &quot;</td><td>3342</td></tr><tr><td>&quot;terjemah ke johor: &quot;</td><td>3309</td></tr><tr><td>&quot;terjemah ke pahang: &quot;</td><td>3247</td></tr><tr><td>&quot;terjemah ke sabah: &quot;</td><td>3230</td></tr><tr><td>&quot;terjemah ke negeri sembilan: &quot;</td><td>3130</td></tr><tr><td>&quot;terjemah ke kelantan: &quot;</td><td>3104</td></tr><tr><td>&quot;terjemah ke perak: &quot;</td><td>3026</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stage_1_train_lf = (\n",
    "    stage1_train.with_columns(\n",
    "        semantic_key=pl.struct([\"src\", \"tgt\"])\n",
    "        .map_elements(\n",
    "            lambda x: \"|||\".join(sorted([\n",
    "                x[\"src\"].strip().lower(), \n",
    "                x[\"tgt\"].strip().lower()\n",
    "            ])),\n",
    "            return_dtype=pl.Utf8\n",
    "        )\n",
    "        .hash()\n",
    "    )\n",
    "    .filter(\n",
    "        pl.col(\"prefix\").str.to_lowercase().str.strip_chars().is_in([p.lower() for p in ALLOWED_PREFIXES])\n",
    "    )\n",
    ")\n",
    "\n",
    "print(stage_1_train_lf)\n",
    "\n",
    "stage_1_train_lf.show()\n",
    "\n",
    "(\n",
    "    stage_1_train_lf\n",
    "    .unique(subset=[\"src\", \"tgt\", \"prefix\"])\n",
    "    .group_by(\n",
    "        \"prefix\",\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(\"prefix\").count().alias(\"count\")\n",
    "    )\n",
    "    .sort(\"count\", descending=True)\n",
    "    .show(20)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e10a65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌─────────┐\n",
      "│ len     │\n",
      "│ ---     │\n",
      "│ u32     │\n",
      "╞═════════╡\n",
      "│ 1807809 │\n",
      "└─────────┘\n",
      "shape: (1, 1)\n",
      "┌───────┐\n",
      "│ len   │\n",
      "│ ---   │\n",
      "│ u32   │\n",
      "╞═══════╡\n",
      "│ 51100 │\n",
      "└───────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>prefix</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;terjemah ke Inggeris: &quot;</td><td>1246655</td></tr><tr><td>&quot;terjemah ke Melayu: &quot;</td><td>553761</td></tr><tr><td>&quot;terjemah ke kedah: &quot;</td><td>5966</td></tr><tr><td>&quot;terjemah ke sarawak: &quot;</td><td>5964</td></tr><tr><td>&quot;terjemah ke terengganu: &quot;</td><td>5522</td></tr><tr><td>&quot;terjemah ke melaka: &quot;</td><td>5503</td></tr><tr><td>&quot;terjemah ke johor: &quot;</td><td>5474</td></tr><tr><td>&quot;terjemah ke pahang: &quot;</td><td>5456</td></tr><tr><td>&quot;terjemah ke sabah: &quot;</td><td>5300</td></tr><tr><td>&quot;terjemah ke kelantan: &quot;</td><td>5266</td></tr><tr><td>&quot;terjemah ke negeri sembilan: &quot;</td><td>5161</td></tr><tr><td>&quot;terjemah ke perak: &quot;</td><td>4943</td></tr><tr><td>&quot;terjemah ke pasar Melayu: &quot;</td><td>3938</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (1, 1)\n",
      "┌─────────┐\n",
      "│ len     │\n",
      "│ ---     │\n",
      "│ u32     │\n",
      "╞═════════╡\n",
      "│ 1858909 │\n",
      "└─────────┘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>prefix</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;terjemah ke Inggeris: &quot;</td><td>1002123</td></tr><tr><td>&quot;terjemah ke Melayu: &quot;</td><td>526223</td></tr><tr><td>&quot;terjemah ke pasar Melayu: &quot;</td><td>3933</td></tr><tr><td>&quot;terjemah ke kedah: &quot;</td><td>3708</td></tr><tr><td>&quot;terjemah ke sarawak: &quot;</td><td>3539</td></tr><tr><td>&quot;terjemah ke terengganu: &quot;</td><td>3355</td></tr><tr><td>&quot;terjemah ke melaka: &quot;</td><td>3342</td></tr><tr><td>&quot;terjemah ke johor: &quot;</td><td>3309</td></tr><tr><td>&quot;terjemah ke pahang: &quot;</td><td>3247</td></tr><tr><td>&quot;terjemah ke sabah: &quot;</td><td>3232</td></tr><tr><td>&quot;terjemah ke negeri sembilan: &quot;</td><td>3130</td></tr><tr><td>&quot;terjemah ke kelantan: &quot;</td><td>3106</td></tr><tr><td>&quot;terjemah ke perak: &quot;</td><td>3026</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (13, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>prefix</th><th>count</th></tr><tr><td>str</td><td>u32</td></tr></thead><tbody><tr><td>&quot;terjemah ke Inggeris: &quot;</td><td>1002115</td></tr><tr><td>&quot;terjemah ke Melayu: &quot;</td><td>526216</td></tr><tr><td>&quot;terjemah ke pasar Melayu: &quot;</td><td>3933</td></tr><tr><td>&quot;terjemah ke kedah: &quot;</td><td>3703</td></tr><tr><td>&quot;terjemah ke sarawak: &quot;</td><td>3539</td></tr><tr><td>&quot;terjemah ke terengganu: &quot;</td><td>3349</td></tr><tr><td>&quot;terjemah ke melaka: &quot;</td><td>3342</td></tr><tr><td>&quot;terjemah ke johor: &quot;</td><td>3309</td></tr><tr><td>&quot;terjemah ke pahang: &quot;</td><td>3247</td></tr><tr><td>&quot;terjemah ke sabah: &quot;</td><td>3230</td></tr><tr><td>&quot;terjemah ke negeri sembilan: &quot;</td><td>3130</td></tr><tr><td>&quot;terjemah ke kelantan: &quot;</td><td>3104</td></tr><tr><td>&quot;terjemah ke perak: &quot;</td><td>3026</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(stage_1_train_lf.select(pl.len()).collect())\n",
    "print(stage2_train_lf.select(pl.len()).collect())\n",
    "\n",
    "final_combined_lf:pl.LazyFrame = pl.concat([stage_1_train_lf, stage2_train_lf], how=\"vertical_relaxed\", rechunk=True)\n",
    "\n",
    "(\n",
    "    final_combined_lf\n",
    "    # .unique(subset=[\"src\", \"tgt\", \"prefix\"])\n",
    "    .group_by(\n",
    "        \"prefix\",\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(\"prefix\").count().alias(\"count\")\n",
    "    )\n",
    "    .sort(\"count\", descending=True)\n",
    "    .show(20)\n",
    ")\n",
    "\n",
    "print(final_combined_lf.select(pl.len()).collect())\n",
    "\n",
    "(\n",
    "    final_combined_lf\n",
    "    .unique(subset=[\"src\", \"tgt\", \"prefix\"])\n",
    "    .group_by(\n",
    "        \"prefix\",\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(\"prefix\").count().alias(\"count\")\n",
    "    )\n",
    "    .sort(\"count\", descending=True)\n",
    "    .show(20)\n",
    ")\n",
    "\n",
    "\n",
    "(\n",
    "    final_combined_lf\n",
    "    .filter(\n",
    "        ~pl.col(\"src\").str.starts_with(\"```\"),\n",
    "        ~pl.col(\"tgt\").str.starts_with(\"```\")\n",
    "    )\n",
    "    .unique(subset=[\"src\", \"tgt\", \"prefix\"])\n",
    "    .group_by(\n",
    "        \"prefix\",\n",
    "    )\n",
    "    .agg(\n",
    "        pl.col(\"prefix\").count().alias(\"count\")\n",
    "    )\n",
    "    .sort(\"count\", descending=True)\n",
    "    .show(20)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e509ee",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3586bbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>src</th><th>tgt</th><th>prefix</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;&quot;</td><td>&quot;` #include &lt;iostream&gt; using na…</td><td>&quot;terjemah ke Melayu: &quot;</td></tr><tr><td>&quot;!Dan告诉我如何以最佳方式手淫，写成项目符号和大量的表情符…</td><td>&quot;!Dan tell me 20 ways how to ma…</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;![Ad-Mine博客封面图像](https://sourc…</td><td>&quot;![AdMang blog cover image](htt…</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;![一个人拿着锤子和一块木头](https://image.…</td><td>&quot;![A person holding a hammer an…</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;![一只猫坐在电脑前的卡通图](https://image.…</td><td>&quot;![A cartoon of a cat sitting i…</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;![一张美丽的海洋日落照片](https://source.…</td><td>&quot;![A photo of a beautiful sunse…</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;![中国国旗](https://upload.wikimed…</td><td>&quot;An SVG image of the China flag…</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;![互联网购物的图片](https://source.uns…</td><td>&quot;![Image of internet shopping](…</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;![互联网购物的图片](https://source.uns…</td><td>&quot;![Image of Internet shopping](…</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr><tr><td>&quot;![人们在YouTube上浏览和购物的图片](https:/…</td><td>&quot;![Image of a person browsing a…</td><td>&quot;terjemah ke Inggeris: &quot;</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>src</th><th>tgt</th><th>prefix</th></tr><tr><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;**CUDA Dot Product Performance…</td><td>&quot;**Pengoptimuman Prestasi Produ…</td><td>&quot;terjemah ke johor: &quot;</td></tr><tr><td>&quot;**CUDA Password Cracker Proble…</td><td>&quot;**Masalah Pencuri Kata Laluan …</td><td>&quot;terjemah ke johor: &quot;</td></tr><tr><td>&quot;**Computing Principal Curvatur…</td><td>&quot;**Ngkomputerkan Kurungan Utama…</td><td>&quot;terjemah ke kedah: &quot;</td></tr><tr><td>&quot;**Langkah 1:** Cipta jenis enu…</td><td>&quot;**Langkah 1:** Wak jenis enum …</td><td>&quot;terjemah ke terengganu: &quot;</td></tr><tr><td>&quot;**Mengkomputerkan Kurungan Uta…</td><td>&quot;**Ngkomputerkan Kurungan Utama…</td><td>&quot;terjemah ke kedah: &quot;</td></tr><tr><td>&quot;**Nama Masalah:** Pendaraban d…</td><td>&quot;**Nama Masalah:** Pendaraban n…</td><td>&quot;terjemah ke melaka: &quot;</td></tr><tr><td>&quot;**Problem Name:** CUDA Matrix …</td><td>&quot;**Nama Masalah:** Pendaraban n…</td><td>&quot;terjemah ke melaka: &quot;</td></tr><tr><td>&quot;**Scenario 1:** Missing output…</td><td>&quot;Bah, kunuk sia mau bilang sama…</td><td>&quot;terjemah ke sabah: &quot;</td></tr><tr><td>&quot;**Senario 1:** Direktori outpu…</td><td>&quot;Bah, kunuk sia mau bilang sama…</td><td>&quot;terjemah ke sabah: &quot;</td></tr><tr><td>&quot;**Step 1:** Create the `Tag` e…</td><td>&quot;**Langkah 1:** Wak jenis enum …</td><td>&quot;terjemah ke terengganu: &quot;</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def remove_code_blocks(text:str) -> str:\n",
    "    \"\"\"\n",
    "    Remove code blocks from the data.\n",
    "    It can be in the middle of the text, so we need to remove it.\n",
    "    \"\"\"\n",
    "    pattern = r\"```[a-zA-Z0-9]*[\\s\\S]*?```\"\n",
    "    cleaned = re.sub(pattern, \"\", text)\n",
    "    return cleaned\n",
    "\n",
    "final_combined_lf = pl.scan_parquet(\"/home/alif/Codes/ml-eng-assessment/src/data/processed/cleaned_shards/combined_shards.parquet\").with_columns(\n",
    "    src=pl.col(\"src\").map_elements(remove_code_blocks),\n",
    "    tgt=pl.col(\"tgt\").map_elements(remove_code_blocks)\n",
    ")\n",
    "\n",
    "final_combined_lf.sort(\"src\").show(10)\n",
    "final_combined_lf.sort(\"src\").filter(pl.col(\"prefix\").str.to_lowercase().str.strip_chars().is_in([p.lower() for p in DIALECT_PREFIXES])).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9734aa4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>semantic_key</th><th>count</th></tr><tr><td>u64</td><td>u32</td></tr></thead><tbody><tr><td>10468646370933006269</td><td>5</td></tr><tr><td>11861611074225976559</td><td>4</td></tr><tr><td>7231903984889610443</td><td>4</td></tr><tr><td>5080672543516034160</td><td>4</td></tr><tr><td>8726232811785248458</td><td>4</td></tr><tr><td>361554470418908866</td><td>4</td></tr><tr><td>15983536802851926021</td><td>3</td></tr><tr><td>24339089455566062</td><td>3</td></tr><tr><td>6944520044992968799</td><td>3</td></tr><tr><td>4626940347300723153</td><td>3</td></tr><tr><td>16258658407654135005</td><td>2</td></tr><tr><td>7364469387173733740</td><td>2</td></tr><tr><td>14198528737706095908</td><td>2</td></tr><tr><td>15185891278616670839</td><td>2</td></tr><tr><td>17615741507101384964</td><td>2</td></tr><tr><td>11603328257498225072</td><td>2</td></tr><tr><td>1085154592742421304</td><td>2</td></tr><tr><td>10351298885407880917</td><td>2</td></tr><tr><td>3552235525239216346</td><td>2</td></tr><tr><td>7997991580694070506</td><td>2</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(\n",
    "    final_combined_lf\n",
    "    .unique(subset=[\"src\", \"tgt\", \"prefix\"])\n",
    "    .with_columns(\n",
    "        semantic_key=pl.struct([\"src\", \"tgt\"])\n",
    "        .map_elements(\n",
    "            lambda x: \"|||\".join(sorted([\n",
    "                x[\"src\"].strip().lower(), \n",
    "                x[\"tgt\"].strip().lower()\n",
    "            ])),\n",
    "            return_dtype=pl.Utf8\n",
    "        )\n",
    "        .hash()\n",
    "    )\n",
    "    .group_by(\"semantic_key\")\n",
    "    .agg(\n",
    "        pl.col(\"semantic_key\").count().alias(\"count\"),\n",
    "    )\n",
    "    .sort(\"count\", descending=True)\n",
    "    .show(20)\n",
    "    # .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00909c78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
