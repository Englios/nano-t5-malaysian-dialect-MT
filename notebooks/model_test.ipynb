{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46833da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Dec 12 14:50:07 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.95.02              Driver Version: 581.42         CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 5070 Ti     On  |   00000000:01:00.0  On |                  N/A |\n",
      "| 34%   55C    P0            141W /  300W |    1960MiB /  16303MiB |     50%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e51bae",
   "metadata": {},
   "source": [
    "# Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f803c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mesolitica/nanot5-small-malaysian-cased\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mesolitica/nanot5-small-malaysian-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a399f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dense_act_fn\": \"gelu_new\",\n",
       "  \"dropout_rate\": 0.0,\n",
       "  \"dtype\": \"float32\",\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"gated-gelu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": true,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"num_decoder_layers\": 6,\n",
       "  \"num_heads\": 8,\n",
       "  \"num_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.57.3\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32128\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1d37fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malay: Hari ini saya pergi ke pasar\n",
      "English:  ke Inggeris ke Inggeris Ke Saya Hari Hari Saya Hari Ini Saya Saya Hari Saya Hari Saya: Sayater: Saya Saya Saya Saya Saya saya hari ini saya pergi hari ini hari Ini Saya Hari Saya Saya Hari ini Saya Hari Saya Hari Saya Saya Saya: Saya\n",
      "\n",
      "Malay: Saya suka makan nasi lemak\n",
      "English:  makan nasi Inggeris: Inggeris: Terterterter Inggeris: : makan: Saya: Saya:: Saya makan makan makan: terjemahterjemahanterter: Inggeris: Inggeristerter Inggeris: ( Inggeris: K Inggeris:\n",
      "\n",
      "Malay: Dia sedang membaca buku di perpustakaan\n",
      "English: : Dia sedang membaca buku Dia sedang::ter: Dia sedang sedang membaca dan sedang membaca di perpustakaan di perpustakaan dan Dia sedang Membaca buku di dalam buku di bilik itu sedang membaca Buku di bilik di bilik Dia sedang dan membaca buku di perpustakaan: Dia di sedang membaca::\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" \n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "TRANSLATE_PREFIX = \"terjemah ke Inggeris: \"\n",
    "\n",
    "def translate(text, max_new_tokens=64):\n",
    "    prompt = TRANSLATE_PREFIX + text\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_beams=4,\n",
    "            no_repeat_ngram_size=3,\n",
    "            repetition_penalty=1.1,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "test_sentences = [\n",
    "    \"Hari ini saya pergi ke pasar\",\n",
    "    \"Saya suka makan nasi lemak\",\n",
    "    \"Dia sedang membaca buku di perpustakaan\",\n",
    "]\n",
    "\n",
    "for sent in test_sentences:\n",
    "    eng = translate(sent)\n",
    "    print(f\"Malay: {sent}\\nEnglish: {eng}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e752f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad><extra_id_99>.<extra_id_85>.This is a test.<extra_id_84>.<extra_id_83>..................\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\"This is a test.\", return_tensors=\"pt\").to(device)\n",
    "if \"token_type_ids\" in inputs:\n",
    "    inputs.pop(\"token_type_ids\")\n",
    "out = model.generate(**inputs, max_new_tokens=30)\n",
    "print(tokenizer.decode(out[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406c8e80",
   "metadata": {},
   "source": [
    "# Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d53192",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mesolitica/nanot5-base-malaysian-cased\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"mesolitica/nanot5-base-malaysian-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad51a340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Malay: Hari ini saya pergi ke pasar\n",
      "English:  ini saya pergi ke pasar. Saya pergiterjemahan ke Inggeris: Inggeris: Saya pergi ke pergi Inggeris saya pergi Hari saya pergi saya pergi Inggeris Inggeris Inggeris Saya pergi Saya pergi Inggeris Inggeris ini saya pergi saya pergi Inggeris Inggeris Inggeris Inggeris\n",
      "\n",
      "Malay: Saya suka makan nasi lemak\n",
      "English: : ke Inggeris: Saya suka makan nasi lemak: Inggeris: Inggeris: English: Inggeris Saya Saya sukajemah ke Inggeris: Saya suka: Inggeris Saya suka Saya suka Inggeris: Englishterjemahan ke Inggeris nasi lemak nasi lemak Inggeris: Saya\n",
      "\n",
      "Malay: Dia sedang membaca buku di perpustakaan\n",
      "English:  Dia sedang membaca buku membaca buku di perpustakaan perpustakaan. Inggeris: Inggeris: di perpustakaan Inggeris Inggeris Inggeris ke Inggeris: Dia sedang menulis buku di Perpustakaan: Dia sedang Membaca bukuterjemahan ke Inggeris di perpustakaan membaca buku di perpustakaan Dia sedang Inggeris Inggeris membaca buku\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "TRANSLATE_PREFIX = \"terjemah ke Inggeris: \"\n",
    "\n",
    "def translate(text, max_new_tokens=64):\n",
    "    prompt = TRANSLATE_PREFIX + text\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    if \"token_type_ids\" in inputs:\n",
    "        inputs.pop(\"token_type_ids\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            num_beams=4,\n",
    "            no_repeat_ngram_size=3,\n",
    "            repetition_penalty=1.1,\n",
    "            early_stopping=True,\n",
    "        )\n",
    "    outputs = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return outputs\n",
    "\n",
    "test_sentences = [\n",
    "    \"Hari ini saya pergi ke pasar\",\n",
    "    \"Saya suka makan nasi lemak\",\n",
    "    \"Dia sedang membaca buku di perpustakaan\",\n",
    "]\n",
    "\n",
    "for sent in test_sentences:\n",
    "    eng = translate(sent)\n",
    "    print(f\"Malay: {sent}\\nEnglish: {eng}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
