# Model Arguments
model_name_or_path: "mesolitica/nanot5-small-malaysian-cased"
cache_dir: null

# Data Arguments
train_data_path: "src/data/processed/dataset/train.parquet"
val_data_path: "src/data/processed/dataset/val.parquet"
test_data_path: "src/data/processed/dataset/test.parquet"
max_source_length: 1024
max_target_length: 128
val_max_target_length: null  
pad_to_max_length: false
ignore_pad_token_for_loss: true

# Training Arguments
output_dir: "outputs"
do_train: true
do_eval: true
do_predict: false

# Training hyperparameters
num_train_epochs: 3
per_device_train_batch_size: 8
per_device_eval_batch_size: 8
gradient_accumulation_steps: 1
learning_rate: 5.0e-5
weight_decay: 0.01
warmup_steps: 500
logging_steps: 100
save_steps: 500 
eval_steps: 500
evaluation_strategy: "steps"  # Must be "steps" to match save_strategy
save_strategy: "steps"  # Must match evaluation_strategy when load_best_model_at_end is true  
save_total_limit: 3  
load_best_model_at_end: true  
metric_for_best_model: eval_bleu
greater_is_better: true
save_safetensors: true  

# Generation settings
generation_max_length: 128
generation_num_beams: 4
predict_with_generate: true

# Other settings
seed: 42
fp16: true  
bf16: false 
no_cuda: false 
dataloader_num_workers: 4
remove_unused_columns: false

# Weights & Biases
report_to: ["wandb"]
run_name: "${WANDB_RUN_NAME:-mesolitica-nanot5-translation}"
wandb_project: "${WANDB_PROJECT:-ml-eng-assessment}"
wandb_entity: "${WANDB_ENTITY:-null}"
wandb_api_key: "${WANDB_API_KEY:-null}"

